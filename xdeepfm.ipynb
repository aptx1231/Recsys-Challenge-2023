{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import log_loss, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "\n",
    "from deepctr_torch.models import xDeepFM\n",
    "from deepctr_torch.inputs import SparseFeat, DenseFeat, get_feature_names\n",
    "\n",
    "from deepctr_torch.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.read_csv('./output/96499_xDeepFM_4_Batch256_bins5_only_sparse.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = pd.read_csv('./output/3957_xDeepFM_4_Batch256_bins10_only_sparse.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "a['is_installed'] = (a['is_installed'] + b['is_installed']) / 2\n",
    "a['is_clicked'] = (a['is_clicked'] + b['is_clicked']) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.to_csv('./output/avg_96499_3957.csv', index=False, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import os\n",
    "import re\n",
    "import math\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "from lightgbm import LGBMRegressor, LGBMClassifier\n",
    "from xgboost import XGBRegressor, XGBClassifier\n",
    "from catboost import CatBoostRegressor, CatBoostClassifier\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import catboost as cab\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import cross_val_score, KFold, StratifiedKFold, GridSearchCV\n",
    "from sklearn.decomposition import LatentDirichletAllocation, NMF, TruncatedSVD\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor, GradientBoostingRegressor, HistGradientBoostingRegressor, StackingRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, HistGradientBoostingClassifier, StackingClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "读入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(160973, 80)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = pd.read_csv('data/test/000000000000.csv', sep='\\t')\n",
    "test_data.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3485852, 82)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv('./data/train.csv', sep='\\t')\n",
    "train_data.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f_0</th>\n",
       "      <th>f_1</th>\n",
       "      <th>f_2</th>\n",
       "      <th>f_3</th>\n",
       "      <th>f_4</th>\n",
       "      <th>f_5</th>\n",
       "      <th>f_6</th>\n",
       "      <th>f_7</th>\n",
       "      <th>f_8</th>\n",
       "      <th>f_9</th>\n",
       "      <th>...</th>\n",
       "      <th>f_72</th>\n",
       "      <th>f_73</th>\n",
       "      <th>f_74</th>\n",
       "      <th>f_75</th>\n",
       "      <th>f_76</th>\n",
       "      <th>f_77</th>\n",
       "      <th>f_78</th>\n",
       "      <th>f_79</th>\n",
       "      <th>is_clicked</th>\n",
       "      <th>is_installed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2541188</td>\n",
       "      <td>57</td>\n",
       "      <td>26325</td>\n",
       "      <td>22294</td>\n",
       "      <td>9018</td>\n",
       "      <td>25604</td>\n",
       "      <td>943</td>\n",
       "      <td>27941</td>\n",
       "      <td>19203</td>\n",
       "      <td>21533</td>\n",
       "      <td>...</td>\n",
       "      <td>2.855607</td>\n",
       "      <td>2.284486</td>\n",
       "      <td>0.115692</td>\n",
       "      <td>1.156922</td>\n",
       "      <td>0.269948</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2541440</td>\n",
       "      <td>60</td>\n",
       "      <td>5156</td>\n",
       "      <td>22294</td>\n",
       "      <td>18971</td>\n",
       "      <td>21545</td>\n",
       "      <td>3448</td>\n",
       "      <td>27941</td>\n",
       "      <td>19606</td>\n",
       "      <td>14659</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.156922</td>\n",
       "      <td>0.269948</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2541480</td>\n",
       "      <td>65</td>\n",
       "      <td>30256</td>\n",
       "      <td>22294</td>\n",
       "      <td>11104</td>\n",
       "      <td>21545</td>\n",
       "      <td>20366</td>\n",
       "      <td>27941</td>\n",
       "      <td>19203</td>\n",
       "      <td>31372</td>\n",
       "      <td>...</td>\n",
       "      <td>0.571121</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.156922</td>\n",
       "      <td>0.269948</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2541780</td>\n",
       "      <td>63</td>\n",
       "      <td>17216</td>\n",
       "      <td>7152</td>\n",
       "      <td>15742</td>\n",
       "      <td>21545</td>\n",
       "      <td>23877</td>\n",
       "      <td>27941</td>\n",
       "      <td>19606</td>\n",
       "      <td>869</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.347077</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2541833</td>\n",
       "      <td>60</td>\n",
       "      <td>9317</td>\n",
       "      <td>22294</td>\n",
       "      <td>26866</td>\n",
       "      <td>21545</td>\n",
       "      <td>32370</td>\n",
       "      <td>27941</td>\n",
       "      <td>21218</td>\n",
       "      <td>14659</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.115692</td>\n",
       "      <td>1.156922</td>\n",
       "      <td>0.269948</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 82 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       f_0  f_1    f_2    f_3    f_4    f_5    f_6    f_7    f_8    f_9  ...  \\\n",
       "0  2541188   57  26325  22294   9018  25604    943  27941  19203  21533  ...   \n",
       "1  2541440   60   5156  22294  18971  21545   3448  27941  19606  14659  ...   \n",
       "2  2541480   65  30256  22294  11104  21545  20366  27941  19203  31372  ...   \n",
       "3  2541780   63  17216   7152  15742  21545  23877  27941  19606    869  ...   \n",
       "4  2541833   60   9317  22294  26866  21545  32370  27941  21218  14659  ...   \n",
       "\n",
       "       f_72      f_73      f_74      f_75      f_76  f_77  f_78  f_79  \\\n",
       "0  2.855607  2.284486  0.115692  1.156922  0.269948   0.0   0.0   0.0   \n",
       "1  0.000000  0.000000  0.000000  1.156922  0.269948   0.0   0.0   0.0   \n",
       "2  0.571121  0.000000  0.000000  1.156922  0.269948   0.0   0.0   0.0   \n",
       "3  0.000000  0.000000  0.000000  0.347077  0.000000   0.0   0.0   0.0   \n",
       "4  0.000000  0.000000  0.115692  1.156922  0.269948   0.0   0.0   0.0   \n",
       "\n",
       "   is_clicked  is_installed  \n",
       "0           0             0  \n",
       "1           0             0  \n",
       "2           1             0  \n",
       "3           0             0  \n",
       "4           0             0  \n",
       "\n",
       "[5 rows x 82 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f_0</th>\n",
       "      <th>f_1</th>\n",
       "      <th>f_2</th>\n",
       "      <th>f_3</th>\n",
       "      <th>f_4</th>\n",
       "      <th>f_5</th>\n",
       "      <th>f_6</th>\n",
       "      <th>f_7</th>\n",
       "      <th>f_8</th>\n",
       "      <th>f_9</th>\n",
       "      <th>...</th>\n",
       "      <th>f_70</th>\n",
       "      <th>f_71</th>\n",
       "      <th>f_72</th>\n",
       "      <th>f_73</th>\n",
       "      <th>f_74</th>\n",
       "      <th>f_75</th>\n",
       "      <th>f_76</th>\n",
       "      <th>f_77</th>\n",
       "      <th>f_78</th>\n",
       "      <th>f_79</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>64505</td>\n",
       "      <td>67</td>\n",
       "      <td>26325</td>\n",
       "      <td>7152</td>\n",
       "      <td>21563</td>\n",
       "      <td>19475</td>\n",
       "      <td>31440</td>\n",
       "      <td>27941</td>\n",
       "      <td>21621</td>\n",
       "      <td>14659</td>\n",
       "      <td>...</td>\n",
       "      <td>1.519085</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>64506</td>\n",
       "      <td>67</td>\n",
       "      <td>20095</td>\n",
       "      <td>563</td>\n",
       "      <td>22861</td>\n",
       "      <td>19475</td>\n",
       "      <td>21280</td>\n",
       "      <td>27941</td>\n",
       "      <td>19203</td>\n",
       "      <td>14659</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.115692</td>\n",
       "      <td>1.156922</td>\n",
       "      <td>0.269948</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>64507</td>\n",
       "      <td>67</td>\n",
       "      <td>890</td>\n",
       "      <td>22294</td>\n",
       "      <td>18294</td>\n",
       "      <td>21545</td>\n",
       "      <td>20210</td>\n",
       "      <td>27941</td>\n",
       "      <td>18800</td>\n",
       "      <td>9638</td>\n",
       "      <td>...</td>\n",
       "      <td>0.982995</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.156922</td>\n",
       "      <td>0.269948</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>64508</td>\n",
       "      <td>67</td>\n",
       "      <td>20095</td>\n",
       "      <td>563</td>\n",
       "      <td>22861</td>\n",
       "      <td>25604</td>\n",
       "      <td>21280</td>\n",
       "      <td>27941</td>\n",
       "      <td>18800</td>\n",
       "      <td>14659</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.284486</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.156922</td>\n",
       "      <td>0.269948</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>64509</td>\n",
       "      <td>67</td>\n",
       "      <td>27426</td>\n",
       "      <td>22294</td>\n",
       "      <td>11338</td>\n",
       "      <td>19475</td>\n",
       "      <td>23855</td>\n",
       "      <td>27941</td>\n",
       "      <td>21218</td>\n",
       "      <td>9638</td>\n",
       "      <td>...</td>\n",
       "      <td>0.986040</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.077128</td>\n",
       "      <td>0.077128</td>\n",
       "      <td>0.077128</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     f_0  f_1    f_2    f_3    f_4    f_5    f_6    f_7    f_8    f_9  ...  \\\n",
       "0  64505   67  26325   7152  21563  19475  31440  27941  21621  14659  ...   \n",
       "1  64506   67  20095    563  22861  19475  21280  27941  19203  14659  ...   \n",
       "2  64507   67    890  22294  18294  21545  20210  27941  18800   9638  ...   \n",
       "3  64508   67  20095    563  22861  25604  21280  27941  18800  14659  ...   \n",
       "4  64509   67  27426  22294  11338  19475  23855  27941  21218   9638  ...   \n",
       "\n",
       "       f_70  f_71      f_72  f_73      f_74      f_75      f_76  f_77  f_78  \\\n",
       "0  1.519085   0.0  0.000000   0.0  0.000000  0.000000  0.000000   0.0   0.0   \n",
       "1  0.000000   0.0  0.000000   0.0  0.115692  1.156922  0.269948   0.0   0.0   \n",
       "2  0.982995   0.0  0.000000   0.0  0.000000  1.156922  0.269948   0.0   0.0   \n",
       "3  0.000000   0.0  2.284486   0.0  0.000000  1.156922  0.269948   0.0   0.0   \n",
       "4  0.986040   0.0  0.000000   0.0  0.077128  0.077128  0.077128   0.0   0.0   \n",
       "\n",
       "   f_79  \n",
       "0   0.0  \n",
       "1   0.0  \n",
       "2   0.0  \n",
       "3   0.0  \n",
       "4   0.0  \n",
       "\n",
       "[5 rows x 80 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([train_data, test_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = ['f_{}'.format(i) for i in range(1, 42)]\n",
    "bin_features = ['f_{}'.format(i) for i in range(33, 42)]\n",
    "num_features = ['f_{}'.format(i) for i in range(42, 80)]\n",
    "date_features = ['f_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_features = cat_features\n",
    "dense_features = num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f_42</th>\n",
       "      <th>f_43</th>\n",
       "      <th>f_44</th>\n",
       "      <th>f_45</th>\n",
       "      <th>f_46</th>\n",
       "      <th>f_47</th>\n",
       "      <th>f_48</th>\n",
       "      <th>f_49</th>\n",
       "      <th>f_50</th>\n",
       "      <th>f_51</th>\n",
       "      <th>...</th>\n",
       "      <th>f_70</th>\n",
       "      <th>f_71</th>\n",
       "      <th>f_72</th>\n",
       "      <th>f_73</th>\n",
       "      <th>f_74</th>\n",
       "      <th>f_75</th>\n",
       "      <th>f_76</th>\n",
       "      <th>f_77</th>\n",
       "      <th>f_78</th>\n",
       "      <th>f_79</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3.646825e+06</td>\n",
       "      <td>3.455631e+06</td>\n",
       "      <td>3.646825e+06</td>\n",
       "      <td>3.646825e+06</td>\n",
       "      <td>3.646825e+06</td>\n",
       "      <td>3.646825e+06</td>\n",
       "      <td>3.646825e+06</td>\n",
       "      <td>3.646825e+06</td>\n",
       "      <td>3.646825e+06</td>\n",
       "      <td>3.455631e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>3.455631e+06</td>\n",
       "      <td>3.646825e+06</td>\n",
       "      <td>3.646825e+06</td>\n",
       "      <td>3.646825e+06</td>\n",
       "      <td>3.646825e+06</td>\n",
       "      <td>3.646825e+06</td>\n",
       "      <td>3.646825e+06</td>\n",
       "      <td>3.646825e+06</td>\n",
       "      <td>3.646825e+06</td>\n",
       "      <td>3.646825e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.887600e+01</td>\n",
       "      <td>1.084403e+00</td>\n",
       "      <td>7.365268e-03</td>\n",
       "      <td>9.394906e-03</td>\n",
       "      <td>3.266683e-03</td>\n",
       "      <td>1.258501e-02</td>\n",
       "      <td>2.191617e-02</td>\n",
       "      <td>1.214932e-02</td>\n",
       "      <td>3.404248e-02</td>\n",
       "      <td>9.676367e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.041742e+00</td>\n",
       "      <td>4.324664e-02</td>\n",
       "      <td>8.554965e-01</td>\n",
       "      <td>2.504329e-01</td>\n",
       "      <td>6.511000e-02</td>\n",
       "      <td>1.002406e+00</td>\n",
       "      <td>2.249009e-01</td>\n",
       "      <td>6.870399e-02</td>\n",
       "      <td>1.075348e+00</td>\n",
       "      <td>3.605268e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.260112e+01</td>\n",
       "      <td>9.153970e-01</td>\n",
       "      <td>8.579235e-02</td>\n",
       "      <td>9.854993e-02</td>\n",
       "      <td>5.213730e-02</td>\n",
       "      <td>1.203414e-01</td>\n",
       "      <td>1.397989e-01</td>\n",
       "      <td>9.934114e-02</td>\n",
       "      <td>1.820592e-01</td>\n",
       "      <td>8.557606e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.094155e+00</td>\n",
       "      <td>1.840033e-01</td>\n",
       "      <td>1.288103e+00</td>\n",
       "      <td>5.601684e-01</td>\n",
       "      <td>5.480815e-02</td>\n",
       "      <td>3.558279e-01</td>\n",
       "      <td>9.442490e-02</td>\n",
       "      <td>1.626345e+00</td>\n",
       "      <td>6.895088e+00</td>\n",
       "      <td>3.814547e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.166491e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.930869e+00</td>\n",
       "      <td>7.527682e-04</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.472436e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.559339e-04</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.156922e+00</td>\n",
       "      <td>2.699485e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.037373e+01</td>\n",
       "      <td>1.157403e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>6.783773e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>8.758587e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>5.711215e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.156922e-01</td>\n",
       "      <td>1.156922e+00</td>\n",
       "      <td>2.699485e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.441106e+01</td>\n",
       "      <td>1.739014e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.579169e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>1.456695e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.142243e+00</td>\n",
       "      <td>5.711215e-01</td>\n",
       "      <td>1.156922e-01</td>\n",
       "      <td>1.156922e+00</td>\n",
       "      <td>2.699485e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.348182e+04</td>\n",
       "      <td>1.176025e+02</td>\n",
       "      <td>1.313579e+01</td>\n",
       "      <td>1.427804e+01</td>\n",
       "      <td>5.711215e+00</td>\n",
       "      <td>4.740308e+01</td>\n",
       "      <td>1.542028e+01</td>\n",
       "      <td>1.256467e+01</td>\n",
       "      <td>2.855607e+01</td>\n",
       "      <td>3.072614e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>7.495700e+01</td>\n",
       "      <td>1.713364e+00</td>\n",
       "      <td>5.711215e+00</td>\n",
       "      <td>3.997850e+00</td>\n",
       "      <td>1.156922e-01</td>\n",
       "      <td>1.156922e+00</td>\n",
       "      <td>2.699485e-01</td>\n",
       "      <td>1.121537e+02</td>\n",
       "      <td>4.859995e+02</td>\n",
       "      <td>2.243075e+02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               f_42          f_43          f_44          f_45          f_46  \\\n",
       "count  3.646825e+06  3.455631e+06  3.646825e+06  3.646825e+06  3.646825e+06   \n",
       "mean   1.887600e+01  1.084403e+00  7.365268e-03  9.394906e-03  3.266683e-03   \n",
       "std    4.260112e+01  9.153970e-01  8.579235e-02  9.854993e-02  5.213730e-02   \n",
       "min    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "25%    2.930869e+00  7.527682e-04  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "50%    1.037373e+01  1.157403e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "75%    2.441106e+01  1.739014e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "max    2.348182e+04  1.176025e+02  1.313579e+01  1.427804e+01  5.711215e+00   \n",
       "\n",
       "               f_47          f_48          f_49          f_50          f_51  \\\n",
       "count  3.646825e+06  3.646825e+06  3.646825e+06  3.646825e+06  3.455631e+06   \n",
       "mean   1.258501e-02  2.191617e-02  1.214932e-02  3.404248e-02  9.676367e+00   \n",
       "std    1.203414e-01  1.397989e-01  9.934114e-02  1.820592e-01  8.557606e+00   \n",
       "min    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  1.166491e-06   \n",
       "25%    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  2.472436e+00   \n",
       "50%    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  6.783773e+00   \n",
       "75%    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  1.579169e+01   \n",
       "max    4.740308e+01  1.542028e+01  1.256467e+01  2.855607e+01  3.072614e+01   \n",
       "\n",
       "       ...          f_70          f_71          f_72          f_73  \\\n",
       "count  ...  3.455631e+06  3.646825e+06  3.646825e+06  3.646825e+06   \n",
       "mean   ...  1.041742e+00  4.324664e-02  8.554965e-01  2.504329e-01   \n",
       "std    ...  1.094155e+00  1.840033e-01  1.288103e+00  5.601684e-01   \n",
       "min    ...  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "25%    ...  1.559339e-04  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "50%    ...  8.758587e-01  0.000000e+00  5.711215e-01  0.000000e+00   \n",
       "75%    ...  1.456695e+00  0.000000e+00  1.142243e+00  5.711215e-01   \n",
       "max    ...  7.495700e+01  1.713364e+00  5.711215e+00  3.997850e+00   \n",
       "\n",
       "               f_74          f_75          f_76          f_77          f_78  \\\n",
       "count  3.646825e+06  3.646825e+06  3.646825e+06  3.646825e+06  3.646825e+06   \n",
       "mean   6.511000e-02  1.002406e+00  2.249009e-01  6.870399e-02  1.075348e+00   \n",
       "std    5.480815e-02  3.558279e-01  9.442490e-02  1.626345e+00  6.895088e+00   \n",
       "min    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "25%    0.000000e+00  1.156922e+00  2.699485e-01  0.000000e+00  0.000000e+00   \n",
       "50%    1.156922e-01  1.156922e+00  2.699485e-01  0.000000e+00  0.000000e+00   \n",
       "75%    1.156922e-01  1.156922e+00  2.699485e-01  0.000000e+00  0.000000e+00   \n",
       "max    1.156922e-01  1.156922e+00  2.699485e-01  1.121537e+02  4.859995e+02   \n",
       "\n",
       "               f_79  \n",
       "count  3.646825e+06  \n",
       "mean   3.605268e-01  \n",
       "std    3.814547e+00  \n",
       "min    0.000000e+00  \n",
       "25%    0.000000e+00  \n",
       "50%    0.000000e+00  \n",
       "75%    0.000000e+00  \n",
       "max    2.243075e+02  \n",
       "\n",
       "[8 rows x 38 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[dense_features].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f_42 23481.81553772541\n",
      "f_43 117.60245036343844\n",
      "f_44 13.135793838855793\n",
      "f_45 14.278036781364992\n",
      "f_46 5.7112147125459956\n",
      "f_47 47.403082114131784\n",
      "f_48 15.42027972387419\n",
      "f_49 12.564672367601194\n",
      "f_50 28.556073562729978\n",
      "f_51 30.726134762362477\n",
      "f_52 9.371068634246576\n",
      "f_53 5.0518929674333375\n",
      "f_54 17.238138598799253\n",
      "f_55 71.18927036551102\n",
      "f_56 13.111783274254467\n",
      "f_57 71.18927036551102\n",
      "f_58 68.8755609646012\n",
      "f_59 4523.565856375785\n",
      "f_60 16570.973256982776\n",
      "f_61 1513.4018051210676\n",
      "f_62 1190.5917223050874\n",
      "f_63 1843.5974706186632\n",
      "f_64 415706830424.0\n",
      "f_65 245375.66598079557\n",
      "f_66 97.81664179648071\n",
      "f_67 14.873527568031658\n",
      "f_68 64.96885037542945\n",
      "f_69 39.87544130370358\n",
      "f_70 74.9569994558488\n",
      "f_71 1.7133644137637989\n",
      "f_72 5.711214712545996\n",
      "f_73 3.997850298782197\n",
      "f_74 0.11569220536106882\n",
      "f_75 1.156922053610688\n",
      "f_76 0.2699484791758273\n",
      "f_77 112.15372537291115\n",
      "f_78 485.9994766159483\n",
      "f_79 224.3074507458223\n"
     ]
    }
   ],
   "source": [
    "for feat in dense_features:\n",
    "    print(feat, data[feat].max() - data[feat].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_mean = data[dense_features].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[sparse_features] = data[sparse_features].fillna(-1, )\n",
    "# data[dense_features] = data[dense_features].fillna(0, )\n",
    "data[dense_features] = data[dense_features].fillna(dense_mean, )\n",
    "target = ['is_installed']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feat in sparse_features:\n",
    "    lbe = LabelEncoder()\n",
    "    data[feat] = lbe.fit_transform(data[feat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: 分桶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_bins = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [03:44<00:00,  5.92s/it]\n"
     ]
    }
   ],
   "source": [
    "add_sparse_features = []\n",
    "for fea in tqdm(dense_features, total=len(dense_features)):\n",
    "    discretizer = KBinsDiscretizer(n_bins=dense_bins, encode='ordinal', strategy='kmeans')  # 等频quantile，等宽uniform\n",
    "    data[fea + '_encode'] = discretizer.fit_transform(np.array(data[fea].tolist()).reshape(-1, 1))\n",
    "    add_sparse_features.append(fea + '_encode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_sparse_features = [fea + '_encode' for fea in dense_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "mms = MinMaxScaler(feature_range=(0,1))\n",
    "data[dense_features] = mms.fit_transform(data[dense_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.read_csv('./data/data_bins_10.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f_0</th>\n",
       "      <th>f_1</th>\n",
       "      <th>f_2</th>\n",
       "      <th>f_3</th>\n",
       "      <th>f_4</th>\n",
       "      <th>f_5</th>\n",
       "      <th>f_6</th>\n",
       "      <th>f_7</th>\n",
       "      <th>f_8</th>\n",
       "      <th>f_9</th>\n",
       "      <th>...</th>\n",
       "      <th>f_70_encode</th>\n",
       "      <th>f_71_encode</th>\n",
       "      <th>f_72_encode</th>\n",
       "      <th>f_73_encode</th>\n",
       "      <th>f_74_encode</th>\n",
       "      <th>f_75_encode</th>\n",
       "      <th>f_76_encode</th>\n",
       "      <th>f_77_encode</th>\n",
       "      <th>f_78_encode</th>\n",
       "      <th>f_79_encode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2541188</td>\n",
       "      <td>12</td>\n",
       "      <td>114</td>\n",
       "      <td>4</td>\n",
       "      <td>191</td>\n",
       "      <td>4</td>\n",
       "      <td>155</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2541440</td>\n",
       "      <td>15</td>\n",
       "      <td>21</td>\n",
       "      <td>4</td>\n",
       "      <td>390</td>\n",
       "      <td>3</td>\n",
       "      <td>559</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2541480</td>\n",
       "      <td>20</td>\n",
       "      <td>131</td>\n",
       "      <td>4</td>\n",
       "      <td>228</td>\n",
       "      <td>3</td>\n",
       "      <td>3261</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2541780</td>\n",
       "      <td>18</td>\n",
       "      <td>73</td>\n",
       "      <td>2</td>\n",
       "      <td>317</td>\n",
       "      <td>3</td>\n",
       "      <td>3843</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2541833</td>\n",
       "      <td>15</td>\n",
       "      <td>44</td>\n",
       "      <td>4</td>\n",
       "      <td>519</td>\n",
       "      <td>3</td>\n",
       "      <td>5179</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 120 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       f_0  f_1  f_2  f_3  f_4  f_5   f_6  f_7  f_8  f_9  ...  f_70_encode  \\\n",
       "0  2541188   12  114    4  191    4   155    0    1    4  ...          2.0   \n",
       "1  2541440   15   21    4  390    3   559    0    2    3  ...          1.0   \n",
       "2  2541480   20  131    4  228    3  3261    0    1    6  ...          3.0   \n",
       "3  2541780   18   73    2  317    3  3843    0    2    0  ...          1.0   \n",
       "4  2541833   15   44    4  519    3  5179    0    4    3  ...          1.0   \n",
       "\n",
       "   f_71_encode  f_72_encode  f_73_encode  f_74_encode  f_75_encode  \\\n",
       "0          2.0          4.0          4.0          3.0          9.0   \n",
       "1          0.0          0.0          0.0          0.0          9.0   \n",
       "2          0.0          1.0          0.0          0.0          9.0   \n",
       "3          0.0          0.0          0.0          0.0          3.0   \n",
       "4          0.0          0.0          0.0          3.0          9.0   \n",
       "\n",
       "   f_76_encode  f_77_encode  f_78_encode  f_79_encode  \n",
       "0          7.0          0.0          0.0          0.0  \n",
       "1          7.0          0.0          0.0          0.0  \n",
       "2          7.0          0.0          0.0          0.0  \n",
       "3          0.0          0.0          0.0          0.0  \n",
       "4          7.0          0.0          0.0          0.0  \n",
       "\n",
       "[5 rows x 120 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_dim = 2\n",
    "dense_dim = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fixlen_feature_columns = \\\n",
    "#     [SparseFeat(feat, vocabulary_size=data[feat].nunique(), embedding_dim=sparse_dim) for i, feat in enumerate(sparse_features)] + \\\n",
    "#     [SparseFeat(feat, vocabulary_size=dense_bins, embedding_dim=sparse_dim) for i, feat in enumerate(add_sparse_features)] + \\\n",
    "#     [DenseFeat(feat, dense_dim) for feat in dense_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixlen_feature_columns = \\\n",
    "    [SparseFeat(feat, vocabulary_size=data[feat].nunique(), embedding_dim=sparse_dim) for i, feat in enumerate(sparse_features)] + \\\n",
    "    [SparseFeat(feat, vocabulary_size=dense_bins, embedding_dim=sparse_dim) for i, feat in enumerate(add_sparse_features)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn_feature_columns = fixlen_feature_columns\n",
    "linear_feature_columns = fixlen_feature_columns\n",
    "\n",
    "feature_names = get_feature_names(linear_feature_columns + dnn_feature_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SparseFeat(name='f_1', vocabulary_size=23, embedding_dim=2, use_hash=False, dtype='int32', embedding_name='f_1', group_name='default_group'),\n",
       " SparseFeat(name='f_2', vocabulary_size=139, embedding_dim=2, use_hash=False, dtype='int32', embedding_name='f_2', group_name='default_group'),\n",
       " SparseFeat(name='f_3', vocabulary_size=5, embedding_dim=2, use_hash=False, dtype='int32', embedding_name='f_3', group_name='default_group'),\n",
       " SparseFeat(name='f_4', vocabulary_size=638, embedding_dim=2, use_hash=False, dtype='int32', embedding_name='f_4', group_name='default_group'),\n",
       " SparseFeat(name='f_5', vocabulary_size=6, embedding_dim=2, use_hash=False, dtype='int32', embedding_name='f_5', group_name='default_group'),\n",
       " SparseFeat(name='f_6', vocabulary_size=5234, embedding_dim=2, use_hash=False, dtype='int32', embedding_name='f_6', group_name='default_group'),\n",
       " SparseFeat(name='f_7', vocabulary_size=1, embedding_dim=2, use_hash=False, dtype='int32', embedding_name='f_7', group_name='default_group'),\n",
       " SparseFeat(name='f_8', vocabulary_size=6, embedding_dim=2, use_hash=False, dtype='int32', embedding_name='f_8', group_name='default_group'),\n",
       " SparseFeat(name='f_9', vocabulary_size=7, embedding_dim=2, use_hash=False, dtype='int32', embedding_name='f_9', group_name='default_group'),\n",
       " SparseFeat(name='f_10', vocabulary_size=3, embedding_dim=2, use_hash=False, dtype='int32', embedding_name='f_10', group_name='default_group'),\n",
       " SparseFeat(name='f_11', vocabulary_size=24, embedding_dim=2, use_hash=False, dtype='int32', embedding_name='f_11', group_name='default_group'),\n",
       " SparseFeat(name='f_12', vocabulary_size=26, embedding_dim=2, use_hash=False, dtype='int32', embedding_name='f_12', group_name='default_group'),\n",
       " SparseFeat(name='f_13', vocabulary_size=331, embedding_dim=2, use_hash=False, dtype='int32', embedding_name='f_13', group_name='default_group'),\n",
       " SparseFeat(name='f_14', vocabulary_size=19, embedding_dim=2, use_hash=False, dtype='int32', embedding_name='f_14', group_name='default_group'),\n",
       " SparseFeat(name='f_15', vocabulary_size=5854, embedding_dim=2, use_hash=False, dtype='int32', embedding_name='f_15', group_name='default_group'),\n",
       " SparseFeat(name='f_16', vocabulary_size=12, embedding_dim=2, use_hash=False, dtype='int32', embedding_name='f_16', group_name='default_group'),\n",
       " SparseFeat(name='f_17', vocabulary_size=49, embedding_dim=2, use_hash=False, dtype='int32', embedding_name='f_17', group_name='default_group'),\n",
       " SparseFeat(name='f_18', vocabulary_size=924, embedding_dim=2, use_hash=False, dtype='int32', embedding_name='f_18', group_name='default_group'),\n",
       " SparseFeat(name='f_19', vocabulary_size=19, embedding_dim=2, use_hash=False, dtype='int32', embedding_name='f_19', group_name='default_group'),\n",
       " SparseFeat(name='f_20', vocabulary_size=57, embedding_dim=2, use_hash=False, dtype='int32', embedding_name='f_20', group_name='default_group'),\n",
       " SparseFeat(name='f_21', vocabulary_size=35, embedding_dim=2, use_hash=False, dtype='int32', embedding_name='f_21', group_name='default_group'),\n",
       " SparseFeat(name='f_22', vocabulary_size=26, embedding_dim=2, use_hash=False, dtype='int32', embedding_name='f_22', group_name='default_group'),\n",
       " SparseFeat(name='f_23', vocabulary_size=4, embedding_dim=2, use_hash=False, dtype='int32', embedding_name='f_23', group_name='default_group'),\n",
       " SparseFeat(name='f_24', vocabulary_size=4, embedding_dim=2, use_hash=False, dtype='int32', embedding_name='f_24', group_name='default_group'),\n",
       " SparseFeat(name='f_25', vocabulary_size=3, embedding_dim=2, use_hash=False, dtype='int32', embedding_name='f_25', group_name='default_group'),\n",
       " SparseFeat(name='f_26', vocabulary_size=2, embedding_dim=2, use_hash=False, dtype='int32', embedding_name='f_26', group_name='default_group'),\n",
       " SparseFeat(name='f_27', vocabulary_size=2, embedding_dim=2, use_hash=False, dtype='int32', embedding_name='f_27', group_name='default_group'),\n",
       " SparseFeat(name='f_28', vocabulary_size=2, embedding_dim=2, use_hash=False, dtype='int32', embedding_name='f_28', group_name='default_group'),\n",
       " SparseFeat(name='f_29', vocabulary_size=2, embedding_dim=2, use_hash=False, dtype='int32', embedding_name='f_29', group_name='default_group'),\n",
       " SparseFeat(name='f_30', vocabulary_size=3, embedding_dim=2, use_hash=False, dtype='int32', embedding_name='f_30', group_name='default_group'),\n",
       " SparseFeat(name='f_31', vocabulary_size=3, embedding_dim=2, use_hash=False, dtype='int32', embedding_name='f_31', group_name='default_group'),\n",
       " SparseFeat(name='f_32', vocabulary_size=4, embedding_dim=2, use_hash=False, dtype='int32', embedding_name='f_32', group_name='default_group'),\n",
       " SparseFeat(name='f_33', vocabulary_size=2, embedding_dim=2, use_hash=False, dtype='int32', embedding_name='f_33', group_name='default_group'),\n",
       " SparseFeat(name='f_34', vocabulary_size=2, embedding_dim=2, use_hash=False, dtype='int32', embedding_name='f_34', group_name='default_group'),\n",
       " SparseFeat(name='f_35', vocabulary_size=2, embedding_dim=2, use_hash=False, dtype='int32', embedding_name='f_35', group_name='default_group'),\n",
       " SparseFeat(name='f_36', vocabulary_size=2, embedding_dim=2, use_hash=False, dtype='int32', embedding_name='f_36', group_name='default_group'),\n",
       " SparseFeat(name='f_37', vocabulary_size=2, embedding_dim=2, use_hash=False, dtype='int32', embedding_name='f_37', group_name='default_group'),\n",
       " SparseFeat(name='f_38', vocabulary_size=2, embedding_dim=2, use_hash=False, dtype='int32', embedding_name='f_38', group_name='default_group'),\n",
       " SparseFeat(name='f_39', vocabulary_size=2, embedding_dim=2, use_hash=False, dtype='int32', embedding_name='f_39', group_name='default_group'),\n",
       " SparseFeat(name='f_40', vocabulary_size=2, embedding_dim=2, use_hash=False, dtype='int32', embedding_name='f_40', group_name='default_group'),\n",
       " SparseFeat(name='f_41', vocabulary_size=2, embedding_dim=2, use_hash=False, dtype='int32', embedding_name='f_41', group_name='default_group'),\n",
       " SparseFeat(name='f_42_encode', vocabulary_size=10, embedding_dim=2, use_hash=False, dtype='int32', embedding_name='f_42_encode', group_name='default_group'),\n",
       " SparseFeat(name='f_43_encode', vocabulary_size=10, embedding_dim=2, use_hash=False, dtype='int32', embedding_name='f_43_encode', group_name='default_group'),\n",
       " SparseFeat(name='f_44_encode', vocabulary_size=10, embedding_dim=2, use_hash=False, dtype='int32', embedding_name='f_44_encode', group_name='default_group'),\n",
       " SparseFeat(name='f_45_encode', vocabulary_size=10, embedding_dim=2, use_hash=False, dtype='int32', embedding_name='f_45_encode', group_name='default_group'),\n",
       " SparseFeat(name='f_46_encode', vocabulary_size=10, embedding_dim=2, use_hash=False, dtype='int32', embedding_name='f_46_encode', group_name='default_group'),\n",
       " SparseFeat(name='f_47_encode', vocabulary_size=10, embedding_dim=2, use_hash=False, dtype='int32', embedding_name='f_47_encode', group_name='default_group'),\n",
       " SparseFeat(name='f_48_encode', vocabulary_size=10, embedding_dim=2, use_hash=False, dtype='int32', embedding_name='f_48_encode', group_name='default_group'),\n",
       " SparseFeat(name='f_49_encode', vocabulary_size=10, embedding_dim=2, use_hash=False, dtype='int32', embedding_name='f_49_encode', group_name='default_group'),\n",
       " SparseFeat(name='f_50_encode', vocabulary_size=10, embedding_dim=2, use_hash=False, dtype='int32', embedding_name='f_50_encode', group_name='default_group'),\n",
       " SparseFeat(name='f_51_encode', vocabulary_size=10, embedding_dim=2, use_hash=False, dtype='int32', embedding_name='f_51_encode', group_name='default_group'),\n",
       " SparseFeat(name='f_52_encode', vocabulary_size=10, embedding_dim=2, use_hash=False, dtype='int32', embedding_name='f_52_encode', group_name='default_group'),\n",
       " SparseFeat(name='f_53_encode', vocabulary_size=10, embedding_dim=2, use_hash=False, dtype='int32', embedding_name='f_53_encode', group_name='default_group'),\n",
       " SparseFeat(name='f_54_encode', vocabulary_size=10, embedding_dim=2, use_hash=False, dtype='int32', embedding_name='f_54_encode', group_name='default_group'),\n",
       " SparseFeat(name='f_55_encode', vocabulary_size=10, embedding_dim=2, use_hash=False, dtype='int32', embedding_name='f_55_encode', group_name='default_group'),\n",
       " SparseFeat(name='f_56_encode', vocabulary_size=10, embedding_dim=2, use_hash=False, dtype='int32', embedding_name='f_56_encode', group_name='default_group'),\n",
       " SparseFeat(name='f_57_encode', vocabulary_size=10, embedding_dim=2, use_hash=False, dtype='int32', embedding_name='f_57_encode', group_name='default_group'),\n",
       " SparseFeat(name='f_58_encode', vocabulary_size=10, embedding_dim=2, use_hash=False, dtype='int32', embedding_name='f_58_encode', group_name='default_group'),\n",
       " SparseFeat(name='f_59_encode', vocabulary_size=10, embedding_dim=2, use_hash=False, dtype='int32', embedding_name='f_59_encode', group_name='default_group'),\n",
       " SparseFeat(name='f_60_encode', vocabulary_size=10, embedding_dim=2, use_hash=False, dtype='int32', embedding_name='f_60_encode', group_name='default_group'),\n",
       " SparseFeat(name='f_61_encode', vocabulary_size=10, embedding_dim=2, use_hash=False, dtype='int32', embedding_name='f_61_encode', group_name='default_group'),\n",
       " SparseFeat(name='f_62_encode', vocabulary_size=10, embedding_dim=2, use_hash=False, dtype='int32', embedding_name='f_62_encode', group_name='default_group'),\n",
       " SparseFeat(name='f_63_encode', vocabulary_size=10, embedding_dim=2, use_hash=False, dtype='int32', embedding_name='f_63_encode', group_name='default_group'),\n",
       " SparseFeat(name='f_64_encode', vocabulary_size=10, embedding_dim=2, use_hash=False, dtype='int32', embedding_name='f_64_encode', group_name='default_group'),\n",
       " SparseFeat(name='f_65_encode', vocabulary_size=10, embedding_dim=2, use_hash=False, dtype='int32', embedding_name='f_65_encode', group_name='default_group'),\n",
       " SparseFeat(name='f_66_encode', vocabulary_size=10, embedding_dim=2, use_hash=False, dtype='int32', embedding_name='f_66_encode', group_name='default_group'),\n",
       " SparseFeat(name='f_67_encode', vocabulary_size=10, embedding_dim=2, use_hash=False, dtype='int32', embedding_name='f_67_encode', group_name='default_group'),\n",
       " SparseFeat(name='f_68_encode', vocabulary_size=10, embedding_dim=2, use_hash=False, dtype='int32', embedding_name='f_68_encode', group_name='default_group'),\n",
       " SparseFeat(name='f_69_encode', vocabulary_size=10, embedding_dim=2, use_hash=False, dtype='int32', embedding_name='f_69_encode', group_name='default_group'),\n",
       " SparseFeat(name='f_70_encode', vocabulary_size=10, embedding_dim=2, use_hash=False, dtype='int32', embedding_name='f_70_encode', group_name='default_group'),\n",
       " SparseFeat(name='f_71_encode', vocabulary_size=10, embedding_dim=2, use_hash=False, dtype='int32', embedding_name='f_71_encode', group_name='default_group'),\n",
       " SparseFeat(name='f_72_encode', vocabulary_size=10, embedding_dim=2, use_hash=False, dtype='int32', embedding_name='f_72_encode', group_name='default_group'),\n",
       " SparseFeat(name='f_73_encode', vocabulary_size=10, embedding_dim=2, use_hash=False, dtype='int32', embedding_name='f_73_encode', group_name='default_group'),\n",
       " SparseFeat(name='f_74_encode', vocabulary_size=10, embedding_dim=2, use_hash=False, dtype='int32', embedding_name='f_74_encode', group_name='default_group'),\n",
       " SparseFeat(name='f_75_encode', vocabulary_size=10, embedding_dim=2, use_hash=False, dtype='int32', embedding_name='f_75_encode', group_name='default_group'),\n",
       " SparseFeat(name='f_76_encode', vocabulary_size=10, embedding_dim=2, use_hash=False, dtype='int32', embedding_name='f_76_encode', group_name='default_group'),\n",
       " SparseFeat(name='f_77_encode', vocabulary_size=10, embedding_dim=2, use_hash=False, dtype='int32', embedding_name='f_77_encode', group_name='default_group'),\n",
       " SparseFeat(name='f_78_encode', vocabulary_size=10, embedding_dim=2, use_hash=False, dtype='int32', embedding_name='f_78_encode', group_name='default_group'),\n",
       " SparseFeat(name='f_79_encode', vocabulary_size=10, embedding_dim=2, use_hash=False, dtype='int32', embedding_name='f_79_encode', group_name='default_group')]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fixlen_feature_columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "单模训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 2023\n",
    "device = 'cuda:2'\n",
    "model_name = 'xDeepFM'\n",
    "batch_size = 256\n",
    "epochs = 50\n",
    "patience = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data[~data['is_clicked'].isna()]\n",
    "test = data[data['is_clicked'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model_input = {name: train[name] for name in feature_names}\n",
    "test_model_input = {name: test[name] for name in feature_names}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = xDeepFM(linear_feature_columns, dnn_feature_columns, task='binary', device=device, seed=seed)\n",
    "model.compile(\"adam\", \"binary_crossentropy\", metrics=['binary_crossentropy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "xDeepFM(\n",
       "  (embedding_dict): ModuleDict(\n",
       "    (f_1): Embedding(23, 2)\n",
       "    (f_2): Embedding(139, 2)\n",
       "    (f_3): Embedding(5, 2)\n",
       "    (f_4): Embedding(638, 2)\n",
       "    (f_5): Embedding(6, 2)\n",
       "    (f_6): Embedding(5234, 2)\n",
       "    (f_7): Embedding(1, 2)\n",
       "    (f_8): Embedding(6, 2)\n",
       "    (f_9): Embedding(7, 2)\n",
       "    (f_10): Embedding(3, 2)\n",
       "    (f_11): Embedding(24, 2)\n",
       "    (f_12): Embedding(26, 2)\n",
       "    (f_13): Embedding(331, 2)\n",
       "    (f_14): Embedding(19, 2)\n",
       "    (f_15): Embedding(5854, 2)\n",
       "    (f_16): Embedding(12, 2)\n",
       "    (f_17): Embedding(49, 2)\n",
       "    (f_18): Embedding(924, 2)\n",
       "    (f_19): Embedding(19, 2)\n",
       "    (f_20): Embedding(57, 2)\n",
       "    (f_21): Embedding(35, 2)\n",
       "    (f_22): Embedding(26, 2)\n",
       "    (f_23): Embedding(4, 2)\n",
       "    (f_24): Embedding(4, 2)\n",
       "    (f_25): Embedding(3, 2)\n",
       "    (f_26): Embedding(2, 2)\n",
       "    (f_27): Embedding(2, 2)\n",
       "    (f_28): Embedding(2, 2)\n",
       "    (f_29): Embedding(2, 2)\n",
       "    (f_30): Embedding(3, 2)\n",
       "    (f_31): Embedding(3, 2)\n",
       "    (f_32): Embedding(4, 2)\n",
       "    (f_33): Embedding(2, 2)\n",
       "    (f_34): Embedding(2, 2)\n",
       "    (f_35): Embedding(2, 2)\n",
       "    (f_36): Embedding(2, 2)\n",
       "    (f_37): Embedding(2, 2)\n",
       "    (f_38): Embedding(2, 2)\n",
       "    (f_39): Embedding(2, 2)\n",
       "    (f_40): Embedding(2, 2)\n",
       "    (f_41): Embedding(2, 2)\n",
       "    (f_42_encode): Embedding(10, 2)\n",
       "    (f_43_encode): Embedding(10, 2)\n",
       "    (f_44_encode): Embedding(10, 2)\n",
       "    (f_45_encode): Embedding(10, 2)\n",
       "    (f_46_encode): Embedding(10, 2)\n",
       "    (f_47_encode): Embedding(10, 2)\n",
       "    (f_48_encode): Embedding(10, 2)\n",
       "    (f_49_encode): Embedding(10, 2)\n",
       "    (f_50_encode): Embedding(10, 2)\n",
       "    (f_51_encode): Embedding(10, 2)\n",
       "    (f_52_encode): Embedding(10, 2)\n",
       "    (f_53_encode): Embedding(10, 2)\n",
       "    (f_54_encode): Embedding(10, 2)\n",
       "    (f_55_encode): Embedding(10, 2)\n",
       "    (f_56_encode): Embedding(10, 2)\n",
       "    (f_57_encode): Embedding(10, 2)\n",
       "    (f_58_encode): Embedding(10, 2)\n",
       "    (f_59_encode): Embedding(10, 2)\n",
       "    (f_60_encode): Embedding(10, 2)\n",
       "    (f_61_encode): Embedding(10, 2)\n",
       "    (f_62_encode): Embedding(10, 2)\n",
       "    (f_63_encode): Embedding(10, 2)\n",
       "    (f_64_encode): Embedding(10, 2)\n",
       "    (f_65_encode): Embedding(10, 2)\n",
       "    (f_66_encode): Embedding(10, 2)\n",
       "    (f_67_encode): Embedding(10, 2)\n",
       "    (f_68_encode): Embedding(10, 2)\n",
       "    (f_69_encode): Embedding(10, 2)\n",
       "    (f_70_encode): Embedding(10, 2)\n",
       "    (f_71_encode): Embedding(10, 2)\n",
       "    (f_72_encode): Embedding(10, 2)\n",
       "    (f_73_encode): Embedding(10, 2)\n",
       "    (f_74_encode): Embedding(10, 2)\n",
       "    (f_75_encode): Embedding(10, 2)\n",
       "    (f_76_encode): Embedding(10, 2)\n",
       "    (f_77_encode): Embedding(10, 2)\n",
       "    (f_78_encode): Embedding(10, 2)\n",
       "    (f_79_encode): Embedding(10, 2)\n",
       "  )\n",
       "  (linear_model): Linear(\n",
       "    (embedding_dict): ModuleDict(\n",
       "      (f_1): Embedding(23, 1)\n",
       "      (f_2): Embedding(139, 1)\n",
       "      (f_3): Embedding(5, 1)\n",
       "      (f_4): Embedding(638, 1)\n",
       "      (f_5): Embedding(6, 1)\n",
       "      (f_6): Embedding(5234, 1)\n",
       "      (f_7): Embedding(1, 1)\n",
       "      (f_8): Embedding(6, 1)\n",
       "      (f_9): Embedding(7, 1)\n",
       "      (f_10): Embedding(3, 1)\n",
       "      (f_11): Embedding(24, 1)\n",
       "      (f_12): Embedding(26, 1)\n",
       "      (f_13): Embedding(331, 1)\n",
       "      (f_14): Embedding(19, 1)\n",
       "      (f_15): Embedding(5854, 1)\n",
       "      (f_16): Embedding(12, 1)\n",
       "      (f_17): Embedding(49, 1)\n",
       "      (f_18): Embedding(924, 1)\n",
       "      (f_19): Embedding(19, 1)\n",
       "      (f_20): Embedding(57, 1)\n",
       "      (f_21): Embedding(35, 1)\n",
       "      (f_22): Embedding(26, 1)\n",
       "      (f_23): Embedding(4, 1)\n",
       "      (f_24): Embedding(4, 1)\n",
       "      (f_25): Embedding(3, 1)\n",
       "      (f_26): Embedding(2, 1)\n",
       "      (f_27): Embedding(2, 1)\n",
       "      (f_28): Embedding(2, 1)\n",
       "      (f_29): Embedding(2, 1)\n",
       "      (f_30): Embedding(3, 1)\n",
       "      (f_31): Embedding(3, 1)\n",
       "      (f_32): Embedding(4, 1)\n",
       "      (f_33): Embedding(2, 1)\n",
       "      (f_34): Embedding(2, 1)\n",
       "      (f_35): Embedding(2, 1)\n",
       "      (f_36): Embedding(2, 1)\n",
       "      (f_37): Embedding(2, 1)\n",
       "      (f_38): Embedding(2, 1)\n",
       "      (f_39): Embedding(2, 1)\n",
       "      (f_40): Embedding(2, 1)\n",
       "      (f_41): Embedding(2, 1)\n",
       "      (f_42_encode): Embedding(10, 1)\n",
       "      (f_43_encode): Embedding(10, 1)\n",
       "      (f_44_encode): Embedding(10, 1)\n",
       "      (f_45_encode): Embedding(10, 1)\n",
       "      (f_46_encode): Embedding(10, 1)\n",
       "      (f_47_encode): Embedding(10, 1)\n",
       "      (f_48_encode): Embedding(10, 1)\n",
       "      (f_49_encode): Embedding(10, 1)\n",
       "      (f_50_encode): Embedding(10, 1)\n",
       "      (f_51_encode): Embedding(10, 1)\n",
       "      (f_52_encode): Embedding(10, 1)\n",
       "      (f_53_encode): Embedding(10, 1)\n",
       "      (f_54_encode): Embedding(10, 1)\n",
       "      (f_55_encode): Embedding(10, 1)\n",
       "      (f_56_encode): Embedding(10, 1)\n",
       "      (f_57_encode): Embedding(10, 1)\n",
       "      (f_58_encode): Embedding(10, 1)\n",
       "      (f_59_encode): Embedding(10, 1)\n",
       "      (f_60_encode): Embedding(10, 1)\n",
       "      (f_61_encode): Embedding(10, 1)\n",
       "      (f_62_encode): Embedding(10, 1)\n",
       "      (f_63_encode): Embedding(10, 1)\n",
       "      (f_64_encode): Embedding(10, 1)\n",
       "      (f_65_encode): Embedding(10, 1)\n",
       "      (f_66_encode): Embedding(10, 1)\n",
       "      (f_67_encode): Embedding(10, 1)\n",
       "      (f_68_encode): Embedding(10, 1)\n",
       "      (f_69_encode): Embedding(10, 1)\n",
       "      (f_70_encode): Embedding(10, 1)\n",
       "      (f_71_encode): Embedding(10, 1)\n",
       "      (f_72_encode): Embedding(10, 1)\n",
       "      (f_73_encode): Embedding(10, 1)\n",
       "      (f_74_encode): Embedding(10, 1)\n",
       "      (f_75_encode): Embedding(10, 1)\n",
       "      (f_76_encode): Embedding(10, 1)\n",
       "      (f_77_encode): Embedding(10, 1)\n",
       "      (f_78_encode): Embedding(10, 1)\n",
       "      (f_79_encode): Embedding(10, 1)\n",
       "    )\n",
       "  )\n",
       "  (out): PredictionLayer()\n",
       "  (dnn): DNN(\n",
       "    (dropout): Dropout(p=0, inplace=False)\n",
       "    (linears): ModuleList(\n",
       "      (0): Linear(in_features=158, out_features=256, bias=True)\n",
       "      (1): Linear(in_features=256, out_features=256, bias=True)\n",
       "    )\n",
       "    (activation_layers): ModuleList(\n",
       "      (0): ReLU(inplace=True)\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (dnn_linear): Linear(in_features=256, out_features=1, bias=False)\n",
       "  (cin): CIN(\n",
       "    (activation): ReLU(inplace=True)\n",
       "    (conv1ds): ModuleList(\n",
       "      (0): Conv1d(6241, 256, kernel_size=(1,), stride=(1,))\n",
       "      (1): Conv1d(10112, 128, kernel_size=(1,), stride=(1,))\n",
       "    )\n",
       "  )\n",
       "  (cin_linear): Linear(in_features=256, out_features=1, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:2\n",
      "Train on 2788681 samples, validate on 697171 samples, 10894 steps per epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10894it [10:59, 16.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "684s - loss:  0.2735 - binary_crossentropy:  0.2735 - val_binary_crossentropy:  0.2659\n",
      "Epoch 00001: val_binary_crossentropy improved from inf to 0.26593, saving model to ckpt/xDeepFM_2_Batch256_bins10_onlysparse.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10894it [10:37, 17.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/50\n",
      "661s - loss:  0.2620 - binary_crossentropy:  0.2620 - val_binary_crossentropy:  0.2613\n",
      "Epoch 00002: val_binary_crossentropy improved from 0.26593 to 0.26131, saving model to ckpt/xDeepFM_2_Batch256_bins10_onlysparse.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10894it [10:56, 16.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/50\n",
      "686s - loss:  0.2581 - binary_crossentropy:  0.2580 - val_binary_crossentropy:  0.2610\n",
      "Epoch 00003: val_binary_crossentropy improved from 0.26131 to 0.26096, saving model to ckpt/xDeepFM_2_Batch256_bins10_onlysparse.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10894it [10:39, 17.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/50\n",
      "663s - loss:  0.2546 - binary_crossentropy:  0.2545 - val_binary_crossentropy:  0.2628\n",
      "Epoch 00004: val_binary_crossentropy did not improve from 0.26096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10894it [10:21, 17.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/50\n",
      "644s - loss:  0.2502 - binary_crossentropy:  0.2501 - val_binary_crossentropy:  0.2638\n",
      "Epoch 00005: val_binary_crossentropy did not improve from 0.26096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10894it [10:29, 17.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/50\n",
      "653s - loss:  0.2447 - binary_crossentropy:  0.2445 - val_binary_crossentropy:  0.2679\n",
      "Epoch 00006: val_binary_crossentropy did not improve from 0.26096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10894it [10:28, 17.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/50\n",
      "652s - loss:  0.2377 - binary_crossentropy:  0.2375 - val_binary_crossentropy:  0.2761\n",
      "Epoch 00007: val_binary_crossentropy did not improve from 0.26096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10894it [10:45, 16.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/50\n",
      "669s - loss:  0.2294 - binary_crossentropy:  0.2292 - val_binary_crossentropy:  0.2869\n",
      "Epoch 00008: val_binary_crossentropy did not improve from 0.26096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10894it [10:08, 17.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/50\n",
      "632s - loss:  0.2202 - binary_crossentropy:  0.2200 - val_binary_crossentropy:  0.3002\n",
      "Epoch 00009: val_binary_crossentropy did not improve from 0.26096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10894it [10:45, 16.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/50\n",
      "669s - loss:  0.2106 - binary_crossentropy:  0.2104 - val_binary_crossentropy:  0.3193\n",
      "Epoch 00010: val_binary_crossentropy did not improve from 0.26096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10894it [10:54, 16.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/50\n",
      "678s - loss:  0.2011 - binary_crossentropy:  0.2008 - val_binary_crossentropy:  0.3402\n",
      "Epoch 00011: val_binary_crossentropy did not improve from 0.26096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10894it [11:06, 16.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/50\n",
      "690s - loss:  0.1918 - binary_crossentropy:  0.1914 - val_binary_crossentropy:  0.3597\n",
      "Epoch 00012: val_binary_crossentropy did not improve from 0.26096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10894it [10:22, 17.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/50\n",
      "646s - loss:  0.1830 - binary_crossentropy:  0.1826 - val_binary_crossentropy:  0.3827\n",
      "Epoch 00013: val_binary_crossentropy did not improve from 0.26096\n",
      "Epoch 00013: early stopping\n"
     ]
    }
   ],
   "source": [
    "es = EarlyStopping(monitor='val_binary_crossentropy', min_delta=0, verbose=1, patience=patience, mode='min')\n",
    "mdckpt = ModelCheckpoint(filepath='ckpt/{}_{}_Batch{}_bins{}_onlysparse.ckpt'.format(model_name, sparse_dim, batch_size, dense_bins), monitor='val_binary_crossentropy', verbose=1, save_best_only=True, mode='min')\n",
    "history = model.fit(train_model_input, train_data[target].values, batch_size=batch_size, epochs=epochs, verbose=1, validation_split=0.2, callbacks=[es,mdckpt])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "单模测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('ckpt/{}_{}_Batch{}_bins{}_onlysparse.ckpt'.format(model_name, sparse_dim, batch_size, dense_bins))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_ans = model.predict(test_model_input, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7.910628596619063e-07, 0.9862615466117859)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_ans.min(), pred_ans.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_oof = model.predict(train_model_input, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logloss: 0.2549, AUC: 0.9146, Precision: 0.7872, Recall: 0.5268, F1 Score: 0.6312\n"
     ]
    }
   ],
   "source": [
    "logloss = metrics.log_loss(train_data[target], pred_oof)\n",
    "acc = metrics.roc_auc_score(train_data[target], pred_oof)\n",
    "precision = metrics.precision_score(train_data[target], [1 if i >= 0.5 else 0 for i in pred_oof])\n",
    "recall = metrics.recall_score(train_data[target], [1 if i >= 0.5 else 0 for i in pred_oof])\n",
    "f1 = metrics.f1_score(train_data[target], [1 if i >= 0.5 else 0 for i in pred_oof])\n",
    "\n",
    "print(f\"Logloss: {logloss:.4f}, AUC: {acc:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame()\n",
    "submission[\"RowId\"] = test_data[\"f_0\"]\n",
    "submission[\"is_clicked\"] = np.random.random((test_data.shape[0]))\n",
    "submission[\"is_installed\"] = pred_ans\n",
    "submission.to_csv('./output/{}_{}_{}_{}_{}_Batch{}_bins{}_onlysparse.csv'.format(model_name, seed, len(feature_names), sparse_dim, dense_dim, batch_size, dense_bins), index=False, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# submission = submission.sort_values(by='RowId', axis=0, ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# submission.to_csv('./output/{}_{}_{}_{}_{}_Batch{}_bins{}_onlysparse_ascending.csv'.format(model_name, seed, len(feature_names), sparse_dim, dense_dim, batch_size, dense_bins), index=False, sep='\\t')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "交叉验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 5\n",
    "seed = 2023\n",
    "device = 'cuda:3'\n",
    "model_name = 'xDeepFM'\n",
    "batch_size = 2048\n",
    "epochs = 50\n",
    "patience = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data[~data['is_installed'].isna()]\n",
    "test = data[data['is_installed'].isna()]\n",
    "label = train['is_installed'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79\n"
     ]
    }
   ],
   "source": [
    "KF = StratifiedKFold(n_splits=K, random_state=seed, shuffle=True)\n",
    "oof_ins = np.zeros(len(train))\n",
    "predictions_ins = np.zeros((len(test)))\n",
    "print(len(feature_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°0\n",
      "xDeepFM 2788681 697171 79\n",
      "cuda:2\n",
      "Train on 2788681 samples, validate on 697171 samples, 1362 steps per epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1362/1362 [02:15<00:00, 10.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "147s - loss:  0.2862 - binary_crossentropy:  0.2862 - val_binary_crossentropy:  0.2723\n",
      "Epoch 00001: val_binary_crossentropy improved from inf to 0.27231, saving model to ckpt/xDeepFM_16_fold0.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1362/1362 [02:12<00:00, 10.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/50\n",
      "143s - loss:  0.2658 - binary_crossentropy:  0.2658 - val_binary_crossentropy:  0.2614\n",
      "Epoch 00002: val_binary_crossentropy improved from 0.27231 to 0.26136, saving model to ckpt/xDeepFM_16_fold0.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1362/1362 [02:14<00:00, 10.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/50\n",
      "145s - loss:  0.2585 - binary_crossentropy:  0.2585 - val_binary_crossentropy:  0.2591\n",
      "Epoch 00003: val_binary_crossentropy improved from 0.26136 to 0.25910, saving model to ckpt/xDeepFM_16_fold0.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1362/1362 [02:10<00:00, 10.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/50\n",
      "141s - loss:  0.2552 - binary_crossentropy:  0.2552 - val_binary_crossentropy:  0.2582\n",
      "Epoch 00004: val_binary_crossentropy improved from 0.25910 to 0.25816, saving model to ckpt/xDeepFM_16_fold0.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1362/1362 [02:12<00:00, 10.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/50\n",
      "143s - loss:  0.2523 - binary_crossentropy:  0.2523 - val_binary_crossentropy:  0.2594\n",
      "Epoch 00005: val_binary_crossentropy did not improve from 0.25816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1362/1362 [02:10<00:00, 10.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/50\n",
      "142s - loss:  0.2496 - binary_crossentropy:  0.2496 - val_binary_crossentropy:  0.2593\n",
      "Epoch 00006: val_binary_crossentropy did not improve from 0.25816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1362/1362 [02:11<00:00, 10.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/50\n",
      "143s - loss:  0.2469 - binary_crossentropy:  0.2469 - val_binary_crossentropy:  0.2605\n",
      "Epoch 00007: val_binary_crossentropy did not improve from 0.25816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1362/1362 [02:10<00:00, 10.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/50\n",
      "141s - loss:  0.2443 - binary_crossentropy:  0.2442 - val_binary_crossentropy:  0.2619\n",
      "Epoch 00008: val_binary_crossentropy did not improve from 0.25816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1362/1362 [02:13<00:00, 10.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/50\n",
      "145s - loss:  0.2419 - binary_crossentropy:  0.2419 - val_binary_crossentropy:  0.2639\n",
      "Epoch 00009: val_binary_crossentropy did not improve from 0.25816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1362/1362 [02:10<00:00, 10.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/50\n",
      "142s - loss:  0.2395 - binary_crossentropy:  0.2394 - val_binary_crossentropy:  0.2655\n",
      "Epoch 00010: val_binary_crossentropy did not improve from 0.25816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1362/1362 [02:12<00:00, 10.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/50\n",
      "144s - loss:  0.2371 - binary_crossentropy:  0.2371 - val_binary_crossentropy:  0.2685\n",
      "Epoch 00011: val_binary_crossentropy did not improve from 0.25816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1362/1362 [02:09<00:00, 10.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/50\n",
      "140s - loss:  0.2348 - binary_crossentropy:  0.2347 - val_binary_crossentropy:  0.2711\n",
      "Epoch 00012: val_binary_crossentropy did not improve from 0.25816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1362/1362 [02:08<00:00, 10.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/50\n",
      "140s - loss:  0.2324 - binary_crossentropy:  0.2324 - val_binary_crossentropy:  0.2745\n",
      "Epoch 00013: val_binary_crossentropy did not improve from 0.25816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1362/1362 [02:12<00:00, 10.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/50\n",
      "143s - loss:  0.2298 - binary_crossentropy:  0.2298 - val_binary_crossentropy:  0.2768\n",
      "Epoch 00014: val_binary_crossentropy did not improve from 0.25816\n",
      "Epoch 00014: early stopping\n",
      "fold n°1\n",
      "xDeepFM 2788681 697171 79\n",
      "cuda:2\n",
      "Train on 2788681 samples, validate on 697171 samples, 1362 steps per epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1362/1362 [02:09<00:00, 10.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "141s - loss:  0.2867 - binary_crossentropy:  0.2867 - val_binary_crossentropy:  0.2714\n",
      "Epoch 00001: val_binary_crossentropy improved from inf to 0.27137, saving model to ckpt/xDeepFM_16_fold1.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1362/1362 [02:11<00:00, 10.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/50\n",
      "142s - loss:  0.2656 - binary_crossentropy:  0.2656 - val_binary_crossentropy:  0.2610\n",
      "Epoch 00002: val_binary_crossentropy improved from 0.27137 to 0.26102, saving model to ckpt/xDeepFM_16_fold1.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1362/1362 [02:06<00:00, 10.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/50\n",
      "138s - loss:  0.2586 - binary_crossentropy:  0.2585 - val_binary_crossentropy:  0.2601\n",
      "Epoch 00003: val_binary_crossentropy improved from 0.26102 to 0.26014, saving model to ckpt/xDeepFM_16_fold1.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1362/1362 [02:07<00:00, 10.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/50\n",
      "138s - loss:  0.2554 - binary_crossentropy:  0.2554 - val_binary_crossentropy:  0.2587\n",
      "Epoch 00004: val_binary_crossentropy improved from 0.26014 to 0.25869, saving model to ckpt/xDeepFM_16_fold1.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1362/1362 [02:07<00:00, 10.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/50\n",
      "139s - loss:  0.2524 - binary_crossentropy:  0.2524 - val_binary_crossentropy:  0.2587\n",
      "Epoch 00005: val_binary_crossentropy improved from 0.25869 to 0.25867, saving model to ckpt/xDeepFM_16_fold1.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1362/1362 [02:08<00:00, 10.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/50\n",
      "139s - loss:  0.2497 - binary_crossentropy:  0.2497 - val_binary_crossentropy:  0.2591\n",
      "Epoch 00006: val_binary_crossentropy did not improve from 0.25867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1362/1362 [02:06<00:00, 10.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/50\n",
      "137s - loss:  0.2469 - binary_crossentropy:  0.2469 - val_binary_crossentropy:  0.2612\n",
      "Epoch 00007: val_binary_crossentropy did not improve from 0.25867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1362/1362 [02:10<00:00, 10.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/50\n",
      "141s - loss:  0.2442 - binary_crossentropy:  0.2442 - val_binary_crossentropy:  0.2623\n",
      "Epoch 00008: val_binary_crossentropy did not improve from 0.25867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1362/1362 [02:08<00:00, 10.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/50\n",
      "139s - loss:  0.2418 - binary_crossentropy:  0.2418 - val_binary_crossentropy:  0.2643\n",
      "Epoch 00009: val_binary_crossentropy did not improve from 0.25867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1362/1362 [02:09<00:00, 10.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/50\n",
      "141s - loss:  0.2395 - binary_crossentropy:  0.2394 - val_binary_crossentropy:  0.2654\n",
      "Epoch 00010: val_binary_crossentropy did not improve from 0.25867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1362/1362 [02:11<00:00, 10.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/50\n",
      "143s - loss:  0.2370 - binary_crossentropy:  0.2370 - val_binary_crossentropy:  0.2679\n",
      "Epoch 00011: val_binary_crossentropy did not improve from 0.25867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1362/1362 [02:08<00:00, 10.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/50\n",
      "139s - loss:  0.2345 - binary_crossentropy:  0.2345 - val_binary_crossentropy:  0.2703\n",
      "Epoch 00012: val_binary_crossentropy did not improve from 0.25867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1362/1362 [02:07<00:00, 10.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/50\n",
      "139s - loss:  0.2320 - binary_crossentropy:  0.2319 - val_binary_crossentropy:  0.2734\n",
      "Epoch 00013: val_binary_crossentropy did not improve from 0.25867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1362/1362 [02:08<00:00, 10.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/50\n",
      "140s - loss:  0.2293 - binary_crossentropy:  0.2292 - val_binary_crossentropy:  0.2784\n",
      "Epoch 00014: val_binary_crossentropy did not improve from 0.25867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1362/1362 [02:07<00:00, 10.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/50\n",
      "138s - loss:  0.2263 - binary_crossentropy:  0.2262 - val_binary_crossentropy:  0.2823\n",
      "Epoch 00015: val_binary_crossentropy did not improve from 0.25867\n",
      "Epoch 00015: early stopping\n",
      "fold n°2\n",
      "xDeepFM 2788682 697170 79\n",
      "cuda:2\n",
      "Train on 2788682 samples, validate on 697170 samples, 1362 steps per epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1362/1362 [02:07<00:00, 10.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "139s - loss:  0.2862 - binary_crossentropy:  0.2862 - val_binary_crossentropy:  0.2723\n",
      "Epoch 00001: val_binary_crossentropy improved from inf to 0.27234, saving model to ckpt/xDeepFM_16_fold2.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1362/1362 [02:08<00:00, 10.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/50\n",
      "140s - loss:  0.2649 - binary_crossentropy:  0.2649 - val_binary_crossentropy:  0.2639\n",
      "Epoch 00002: val_binary_crossentropy improved from 0.27234 to 0.26386, saving model to ckpt/xDeepFM_16_fold2.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1362/1362 [02:08<00:00, 10.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/50\n",
      "140s - loss:  0.2579 - binary_crossentropy:  0.2579 - val_binary_crossentropy:  0.2601\n",
      "Epoch 00003: val_binary_crossentropy improved from 0.26386 to 0.26006, saving model to ckpt/xDeepFM_16_fold2.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1362/1362 [02:10<00:00, 10.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/50\n",
      "141s - loss:  0.2546 - binary_crossentropy:  0.2545 - val_binary_crossentropy:  0.2595\n",
      "Epoch 00004: val_binary_crossentropy improved from 0.26006 to 0.25948, saving model to ckpt/xDeepFM_16_fold2.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1362/1362 [02:08<00:00, 10.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/50\n",
      "140s - loss:  0.2517 - binary_crossentropy:  0.2517 - val_binary_crossentropy:  0.2593\n",
      "Epoch 00005: val_binary_crossentropy improved from 0.25948 to 0.25927, saving model to ckpt/xDeepFM_16_fold2.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1362/1362 [02:11<00:00, 10.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/50\n",
      "142s - loss:  0.2490 - binary_crossentropy:  0.2490 - val_binary_crossentropy:  0.2599\n",
      "Epoch 00006: val_binary_crossentropy did not improve from 0.25927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1362/1362 [02:10<00:00, 10.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/50\n",
      "141s - loss:  0.2461 - binary_crossentropy:  0.2461 - val_binary_crossentropy:  0.2614\n",
      "Epoch 00007: val_binary_crossentropy did not improve from 0.25927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1362/1362 [02:10<00:00, 10.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/50\n",
      "142s - loss:  0.2436 - binary_crossentropy:  0.2435 - val_binary_crossentropy:  0.2646\n",
      "Epoch 00008: val_binary_crossentropy did not improve from 0.25927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1362/1362 [02:07<00:00, 10.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/50\n",
      "139s - loss:  0.2411 - binary_crossentropy:  0.2411 - val_binary_crossentropy:  0.2652\n",
      "Epoch 00009: val_binary_crossentropy did not improve from 0.25927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1362/1362 [02:08<00:00, 10.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/50\n",
      "139s - loss:  0.2388 - binary_crossentropy:  0.2388 - val_binary_crossentropy:  0.2674\n",
      "Epoch 00010: val_binary_crossentropy did not improve from 0.25927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1362/1362 [02:07<00:00, 10.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/50\n",
      "139s - loss:  0.2365 - binary_crossentropy:  0.2365 - val_binary_crossentropy:  0.2694\n",
      "Epoch 00011: val_binary_crossentropy did not improve from 0.25927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1362/1362 [02:08<00:00, 10.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/50\n",
      "141s - loss:  0.2342 - binary_crossentropy:  0.2342 - val_binary_crossentropy:  0.2725\n",
      "Epoch 00012: val_binary_crossentropy did not improve from 0.25927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1362/1362 [02:07<00:00, 10.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/50\n",
      "138s - loss:  0.2318 - binary_crossentropy:  0.2318 - val_binary_crossentropy:  0.2757\n",
      "Epoch 00013: val_binary_crossentropy did not improve from 0.25927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1362/1362 [02:08<00:00, 10.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/50\n",
      "139s - loss:  0.2293 - binary_crossentropy:  0.2292 - val_binary_crossentropy:  0.2797\n",
      "Epoch 00014: val_binary_crossentropy did not improve from 0.25927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1362/1362 [02:10<00:00, 10.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/50\n",
      "142s - loss:  0.2264 - binary_crossentropy:  0.2264 - val_binary_crossentropy:  0.2829\n",
      "Epoch 00015: val_binary_crossentropy did not improve from 0.25927\n",
      "Epoch 00015: early stopping\n",
      "fold n°3\n",
      "xDeepFM 2788682 697170 79\n",
      "cuda:2\n",
      "Train on 2788682 samples, validate on 697170 samples, 1362 steps per epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1362/1362 [02:06<00:00, 10.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "139s - loss:  0.2864 - binary_crossentropy:  0.2864 - val_binary_crossentropy:  0.2714\n",
      "Epoch 00001: val_binary_crossentropy improved from inf to 0.27143, saving model to ckpt/xDeepFM_16_fold3.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1362/1362 [02:09<00:00, 10.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/50\n",
      "141s - loss:  0.2658 - binary_crossentropy:  0.2658 - val_binary_crossentropy:  0.2618\n",
      "Epoch 00002: val_binary_crossentropy improved from 0.27143 to 0.26178, saving model to ckpt/xDeepFM_16_fold3.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1362/1362 [02:08<00:00, 10.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/50\n",
      "140s - loss:  0.2584 - binary_crossentropy:  0.2584 - val_binary_crossentropy:  0.2592\n",
      "Epoch 00003: val_binary_crossentropy improved from 0.26178 to 0.25915, saving model to ckpt/xDeepFM_16_fold3.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1362/1362 [02:08<00:00, 10.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/50\n",
      "139s - loss:  0.2551 - binary_crossentropy:  0.2551 - val_binary_crossentropy:  0.2582\n",
      "Epoch 00004: val_binary_crossentropy improved from 0.25915 to 0.25818, saving model to ckpt/xDeepFM_16_fold3.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1362/1362 [02:07<00:00, 10.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/50\n",
      "139s - loss:  0.2524 - binary_crossentropy:  0.2524 - val_binary_crossentropy:  0.2579\n",
      "Epoch 00005: val_binary_crossentropy improved from 0.25818 to 0.25785, saving model to ckpt/xDeepFM_16_fold3.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1362/1362 [02:11<00:00, 10.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/50\n",
      "143s - loss:  0.2497 - binary_crossentropy:  0.2497 - val_binary_crossentropy:  0.2589\n",
      "Epoch 00006: val_binary_crossentropy did not improve from 0.25785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1362/1362 [02:08<00:00, 10.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/50\n",
      "140s - loss:  0.2471 - binary_crossentropy:  0.2471 - val_binary_crossentropy:  0.2615\n",
      "Epoch 00007: val_binary_crossentropy did not improve from 0.25785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1362/1362 [02:10<00:00, 10.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/50\n",
      "142s - loss:  0.2445 - binary_crossentropy:  0.2445 - val_binary_crossentropy:  0.2611\n",
      "Epoch 00008: val_binary_crossentropy did not improve from 0.25785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1362/1362 [02:08<00:00, 10.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/50\n",
      "140s - loss:  0.2420 - binary_crossentropy:  0.2419 - val_binary_crossentropy:  0.2649\n",
      "Epoch 00009: val_binary_crossentropy did not improve from 0.25785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1362/1362 [02:09<00:00, 10.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/50\n",
      "141s - loss:  0.2396 - binary_crossentropy:  0.2396 - val_binary_crossentropy:  0.2658\n",
      "Epoch 00010: val_binary_crossentropy did not improve from 0.25785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1362/1362 [02:08<00:00, 10.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/50\n",
      "139s - loss:  0.2372 - binary_crossentropy:  0.2372 - val_binary_crossentropy:  0.2687\n",
      "Epoch 00011: val_binary_crossentropy did not improve from 0.25785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1362/1362 [02:08<00:00, 10.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/50\n",
      "140s - loss:  0.2349 - binary_crossentropy:  0.2349 - val_binary_crossentropy:  0.2709\n",
      "Epoch 00012: val_binary_crossentropy did not improve from 0.25785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1362/1362 [02:07<00:00, 10.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/50\n",
      "139s - loss:  0.2326 - binary_crossentropy:  0.2325 - val_binary_crossentropy:  0.2740\n",
      "Epoch 00013: val_binary_crossentropy did not improve from 0.25785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1362/1362 [02:07<00:00, 10.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/50\n",
      "139s - loss:  0.2301 - binary_crossentropy:  0.2300 - val_binary_crossentropy:  0.2776\n",
      "Epoch 00014: val_binary_crossentropy did not improve from 0.25785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1362/1362 [02:10<00:00, 10.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/50\n",
      "142s - loss:  0.2274 - binary_crossentropy:  0.2273 - val_binary_crossentropy:  0.2815\n",
      "Epoch 00015: val_binary_crossentropy did not improve from 0.25785\n",
      "Epoch 00015: early stopping\n",
      "fold n°4\n",
      "xDeepFM 2788682 697170 79\n",
      "cuda:2\n",
      "Train on 2788682 samples, validate on 697170 samples, 1362 steps per epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1362/1362 [02:08<00:00, 10.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "140s - loss:  0.2863 - binary_crossentropy:  0.2863 - val_binary_crossentropy:  0.2708\n",
      "Epoch 00001: val_binary_crossentropy improved from inf to 0.27081, saving model to ckpt/xDeepFM_16_fold4.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1362/1362 [02:11<00:00, 10.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/50\n",
      "143s - loss:  0.2656 - binary_crossentropy:  0.2656 - val_binary_crossentropy:  0.2620\n",
      "Epoch 00002: val_binary_crossentropy improved from 0.27081 to 0.26198, saving model to ckpt/xDeepFM_16_fold4.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1362/1362 [02:08<00:00, 10.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/50\n",
      "140s - loss:  0.2586 - binary_crossentropy:  0.2586 - val_binary_crossentropy:  0.2583\n",
      "Epoch 00003: val_binary_crossentropy improved from 0.26198 to 0.25830, saving model to ckpt/xDeepFM_16_fold4.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1362/1362 [02:16<00:00,  9.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/50\n",
      "148s - loss:  0.2552 - binary_crossentropy:  0.2552 - val_binary_crossentropy:  0.2573\n",
      "Epoch 00004: val_binary_crossentropy improved from 0.25830 to 0.25729, saving model to ckpt/xDeepFM_16_fold4.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1362/1362 [02:09<00:00, 10.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/50\n",
      "141s - loss:  0.2524 - binary_crossentropy:  0.2524 - val_binary_crossentropy:  0.2571\n",
      "Epoch 00005: val_binary_crossentropy improved from 0.25729 to 0.25710, saving model to ckpt/xDeepFM_16_fold4.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1362/1362 [02:12<00:00, 10.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/50\n",
      "144s - loss:  0.2498 - binary_crossentropy:  0.2498 - val_binary_crossentropy:  0.2580\n",
      "Epoch 00006: val_binary_crossentropy did not improve from 0.25710\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1362/1362 [02:08<00:00, 10.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/50\n",
      "140s - loss:  0.2470 - binary_crossentropy:  0.2470 - val_binary_crossentropy:  0.2630\n",
      "Epoch 00007: val_binary_crossentropy did not improve from 0.25710\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1362/1362 [02:11<00:00, 10.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/50\n",
      "142s - loss:  0.2444 - binary_crossentropy:  0.2444 - val_binary_crossentropy:  0.2615\n",
      "Epoch 00008: val_binary_crossentropy did not improve from 0.25710\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1362/1362 [02:08<00:00, 10.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/50\n",
      "139s - loss:  0.2420 - binary_crossentropy:  0.2420 - val_binary_crossentropy:  0.2639\n",
      "Epoch 00009: val_binary_crossentropy did not improve from 0.25710\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1362/1362 [02:10<00:00, 10.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/50\n",
      "141s - loss:  0.2396 - binary_crossentropy:  0.2396 - val_binary_crossentropy:  0.2660\n",
      "Epoch 00010: val_binary_crossentropy did not improve from 0.25710\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1362/1362 [02:08<00:00, 10.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/50\n",
      "140s - loss:  0.2372 - binary_crossentropy:  0.2372 - val_binary_crossentropy:  0.2679\n",
      "Epoch 00011: val_binary_crossentropy did not improve from 0.25710\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1362/1362 [02:11<00:00, 10.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/50\n",
      "142s - loss:  0.2348 - binary_crossentropy:  0.2347 - val_binary_crossentropy:  0.2726\n",
      "Epoch 00012: val_binary_crossentropy did not improve from 0.25710\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1362/1362 [02:07<00:00, 10.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/50\n",
      "139s - loss:  0.2323 - binary_crossentropy:  0.2322 - val_binary_crossentropy:  0.2755\n",
      "Epoch 00013: val_binary_crossentropy did not improve from 0.25710\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1362/1362 [02:05<00:00, 10.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/50\n",
      "137s - loss:  0.2297 - binary_crossentropy:  0.2296 - val_binary_crossentropy:  0.2784\n",
      "Epoch 00014: val_binary_crossentropy did not improve from 0.25710\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1362/1362 [02:09<00:00, 10.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/50\n",
      "140s - loss:  0.2268 - binary_crossentropy:  0.2267 - val_binary_crossentropy:  0.2839\n",
      "Epoch 00015: val_binary_crossentropy did not improve from 0.25710\n",
      "Epoch 00015: early stopping\n"
     ]
    }
   ],
   "source": [
    "for fold_, (trn_idx, val_idx) in enumerate(KF.split(train.values, label.values)):\n",
    "    print(\"fold n°{}\".format(fold_))\n",
    "    \n",
    "    print(model_name, len(trn_idx), len(val_idx), len(feature_names))\n",
    "    train_fold = train.iloc[trn_idx]\n",
    "    train_model_input = {name: train_fold[name] for name in feature_names}\n",
    "    train_model_label = label.iloc[trn_idx].values\n",
    "    val_fold = train.iloc[val_idx]\n",
    "    val_model_input = {name: val_fold[name] for name in feature_names}\n",
    "    val_model_label = label.iloc[val_idx].values\n",
    "    test_model_input = {name: test[name] for name in feature_names}\n",
    "\n",
    "    model = xDeepFM(linear_feature_columns, dnn_feature_columns, task='binary', device=device, seed=seed)\n",
    "    model.compile(\"adam\", \"binary_crossentropy\", metrics=['binary_crossentropy'])\n",
    "    \n",
    "    es = EarlyStopping(monitor='val_binary_crossentropy', min_delta=0, verbose=1, patience=patience, mode='min')\n",
    "    mdckpt = ModelCheckpoint(filepath='ckpt/{}_{}_fold{}.ckpt'.format(model_name, sparse_dim, fold_), \n",
    "                             monitor='val_binary_crossentropy', verbose=1, save_best_only=True, mode='min')\n",
    "    history = model.fit(train_model_input, train_model_label, batch_size=batch_size, epochs=epochs, verbose=1, \n",
    "                        validation_data=(val_model_input, val_model_label), callbacks=[es, mdckpt])\n",
    "\n",
    "    model = torch.load('ckpt/{}_{}_fold{}.ckpt'.format(model_name, sparse_dim, fold_))\n",
    "    oof_ins[val_idx] = model.predict(val_model_input, batch_size=batch_size).flatten()\n",
    "    predictions_ins[:] += model.predict(test_model_input, batch_size=batch_size).flatten() / K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logloss: 0.2582, AUC: 0.9118, Precision: 0.7882, Recall: 0.5204, F1 Score: 0.6269\n"
     ]
    }
   ],
   "source": [
    "logloss = metrics.log_loss(label, oof_ins)\n",
    "acc = metrics.roc_auc_score(label, oof_ins)\n",
    "precision = metrics.precision_score(label, [1 if i >= 0.5 else 0 for i in oof_ins])\n",
    "recall = metrics.recall_score(label, [1 if i >= 0.5 else 0 for i in oof_ins])\n",
    "f1 = metrics.f1_score(label, [1 if i >= 0.5 else 0 for i in oof_ins])\n",
    "\n",
    "print(f\"Logloss: {logloss:.4f}, AUC: {acc:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6.823736111982726e-06, 0.9711936712265015)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_ins.min(), predictions_ins.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame()\n",
    "submission[\"RowId\"] = test_data[\"f_0\"]\n",
    "submission[\"is_clicked\"] = np.random.random((test_data.shape[0]))\n",
    "submission[\"is_installed\"] = predictions_ins\n",
    "submission.to_csv('./output/{}_{}_{}_{}_{}_Kfold{}.csv'.format(model_name, seed, len(feature_names), sparse_dim, dense_dim, K), index=False, sep='\\t')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "111"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "libcityng",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
